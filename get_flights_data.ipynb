{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed21fd9",
   "metadata": {},
   "source": [
    "# How to download flights csv file from transtats website"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac59b93e",
   "metadata": {},
   "source": [
    "**In this notebook, we will**\n",
    "1. Download a csv file for each of your chosen year(s) and month(s)\n",
    "2. Prepare the data for further processing\n",
    "3. Push the prepared data to a table in the database\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b777e805",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import psycopg2 # needed to get database exception errors when uploading dataframe\n",
    "import requests # package for getting data from the web\n",
    "from zipfile import * # package for unzipping zip files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f576d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the get_engine function from our sql_functions.\n",
    "from sql_functions import get_engine #adjust this as necessary to match your sql_functions.py connection methods\n",
    "engine = get_engine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc483e3e",
   "metadata": {},
   "source": [
    "# 1. Download csv file with flight data for your specific year/month"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c3c3fe3",
   "metadata": {},
   "source": [
    "In the following, you are going to download a csv file containing flight data from [this website](https://transtats.bts.gov).    \n",
    "You can specify, which data you want to download. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09d000b",
   "metadata": {},
   "source": [
    "Choose a month/year that you want to explore further.\n",
    "With the following functions, you will download a csv file on public flight data from [this website](https://transtats.bts.gov) containing data of your chosen month/year.    \n",
    "The file will be stored in a data folder.\n",
    "Check out the url from which we download the data(https://transtats.bts.gov/PREZIP). Can we download data in this way from every source? What do you think?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8a61deca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: data/: File exists\n"
     ]
    }
   ],
   "source": [
    "# Specifies path for saving file\n",
    "path ='data/' \n",
    "# Create the data folder\n",
    "!mkdir {path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5dff7a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get specified csv file from the website https://transtats.bts.gov\n",
    "\n",
    "def download_data(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    url = (f'https://transtats.bts.gov/PREZIP/{zip_file}')\n",
    "    # Download the database\n",
    "    r = requests.get(f'{url}', verify=False)\n",
    "    # Save database to local file storage\n",
    "    with open(path+zip_file, 'wb') as f:\n",
    "        f.write(r.content)\n",
    "        print(f'--> zip_file with name: {zip_file} downloaded succesfully.' )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b1588f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to extract the csv files inside the zip files\n",
    "\n",
    "def extract_zip(year, month):\n",
    "    # Get the file from the website https://transtats.bts.gov\n",
    "    zip_file = f'On_Time_Reporting_Carrier_On_Time_Performance_1987_present_{year}_{month}.zip'\n",
    "    with ZipFile(path+zip_file, 'r') as zip_ref:\n",
    "        zip_ref.extractall(path)\n",
    "        csv_file =  zip_ref.namelist()[0]\n",
    "        print(f'--> zip_file was succesfully extracted to: {csv_file}.' )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3c824f",
   "metadata": {},
   "source": [
    "Don't worry - the following download of the data you chose may take some time ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8738fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "years_list = [2018, 2019, 2020, 2021, 2022] # list of years you want to look at (can of course also be a single year)\n",
    "months_list = [1, 12] # list of months you want to look at (can of course also be a single month)\n",
    "\n",
    "# download flights data as zipfile(s)\n",
    "# we use a nested loop to specify the years and months to define the range of the data we would like to have \n",
    "for year in years_list:\n",
    "    for month in months_list:\n",
    "        download_data(year, month)\n",
    "        extract_zip(year, month)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5956edf",
   "metadata": {},
   "source": [
    "Now it is time to load the csv files into dataframes. You can create your own function equivalent to the functions above. But you need to decide whether...\n",
    "\n",
    "- Do you need one dataframe for every month?\n",
    "- Would you like to proceed with only one dataframe containing all the data you downloaded?\n",
    "- One dataframe for every year?\n",
    "\n",
    "There are certain things to consider before.\n",
    "- changing column names\n",
    "- dealing with missing data\n",
    "- changing datatypes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "61a1a079",
   "metadata": {},
   "source": [
    "#### Giving name of CSV for January (2018 until 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82b9ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2018_1 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2018_1.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2018_1 = pd.read_csv(path+csv_file_2018_1, low_memory = False)\n",
    "display(df_2018_1.shape)\n",
    "display(df_2018_1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de351d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2019_1 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2019_1.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2019_1 = pd.read_csv(path+csv_file_2019_1, low_memory = False)\n",
    "display(df_2019_1.shape)\n",
    "display(df_2019_1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3adc2d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2020_1 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2020_1.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2020_1 = pd.read_csv(path+csv_file_2020_1, low_memory = False)\n",
    "display(df_2020_1.shape)\n",
    "display(df_2020_1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c320df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2021_1 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2021_1.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2021_1 = pd.read_csv(path+csv_file_2021_1, low_memory = False)\n",
    "display(df_2021_1.shape)\n",
    "display(df_2021_1.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2022_1 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_1.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2022_1 = pd.read_csv(path+csv_file_2022_1, low_memory = False)\n",
    "display(df_2022_1.shape)\n",
    "display(df_2022_1.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4e4573b5",
   "metadata": {},
   "source": [
    "#### Giving name of CSV for December (2018 until 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd00ac3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2018_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2018_12.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2018_12 = pd.read_csv(path+csv_file_2018_12, low_memory = False)\n",
    "display(df_2018_12.shape)\n",
    "display(df_2018_12.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115e384f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2019_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2019_12.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2019_12 = pd.read_csv(path+csv_file_2019_12, low_memory = False)\n",
    "display(df_2019_12.shape)\n",
    "display(df_2019_12.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439ec13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2020_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2020_12.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2020_12 = pd.read_csv(path+csv_file_2020_12, low_memory = False)\n",
    "display(df_2020_12.shape)\n",
    "display(df_2020_12.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ef5ecc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2021_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2021_12.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2021_12 = pd.read_csv(path+csv_file_2021_12, low_memory = False)\n",
    "display(df_2021_12.shape)\n",
    "display(df_2021_12.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93a2719",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "csv_file_2022_12 = 'On_Time_Reporting_Carrier_On_Time_Performance_(1987_present)_2022_12.csv'\n",
    "\n",
    "# Read in your data\n",
    "df_2022_12 = pd.read_csv(path+csv_file_2022_12, low_memory = False)\n",
    "display(df_2022_12.shape)\n",
    "display(df_2022_12.head(10))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "04b182f1",
   "metadata": {},
   "source": [
    "### Combining all dataframes with concat function (2018 - 2022, December)\n",
    "\n",
    "##### We just decided to focus on December since the data was too large when including January"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "72c1da90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2699942, 110)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"frames = [df_2018_1, df_2018_12, df_2019_1, df_2019_12, df_2020_1, df_2020_12, df_2021_1, df_2021_12, df_2022_1, df_2022_12]\"\"\"\n",
    "\n",
    "frames2 = [df_2018_12, df_2019_12, df_2020_12, df_2021_12, df_2022_12]\n",
    "df = pd.concat(frames2)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84fdf703",
   "metadata": {},
   "source": [
    "# 2. Prepare the csv file for further processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f4e575",
   "metadata": {},
   "source": [
    "In the next step, we clean and prepare our dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "441c52f5",
   "metadata": {},
   "source": [
    "a) Since the dataset consists of a lot of columns, we we define which ones to keep.  \n",
    "(Same as known from our SQL exercises on flights data.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "63c35afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns from downloaded file that are to be kept\n",
    "\n",
    "columns_to_keep = [\n",
    "                'FlightDate',\n",
    "                'DepTime',\n",
    "                'CRSDepTime',\n",
    "                'DepDelay',\n",
    "                'ArrTime',\n",
    "                'CRSArrTime',\n",
    "                'ArrDelay',\n",
    "                'Reporting_Airline',\n",
    "                'Tail_Number',\n",
    "                'Flight_Number_Reporting_Airline',\n",
    "                'Origin',\n",
    "                'Dest',\n",
    "                'AirTime',\n",
    "                'ActualElapsedTime',\n",
    "                'Distance',\n",
    "                'Cancelled',\n",
    "                'Diverted'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "8c182c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('flight_date',),\n",
       " ('dep_time',),\n",
       " ('sched_dep_time',),\n",
       " ('dep_delay',),\n",
       " ('arr_time',),\n",
       " ('sched_arr_time',),\n",
       " ('arr_delay',),\n",
       " ('airline',),\n",
       " ('tail_number',),\n",
       " ('flight_number',),\n",
       " ('origin',),\n",
       " ('dest',),\n",
       " ('air_time',),\n",
       " ('actual_elapsed_time',),\n",
       " ('distance',),\n",
       " ('cancelled',),\n",
       " ('diverted',)]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The columns in the database have different naming as in the source csv files. Lets get the names from the database\n",
    "\n",
    "schema = 'hh_analytics_23_1' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database\n",
    "\n",
    "table_name_sql = f'''SELECT COLUMN_NAME \n",
    "                    FROM INFORMATION_SCHEMA.COLUMNS \n",
    "                    WHERE TABLE_NAME = 'flights'\n",
    "                    AND TABLE_SCHEMA ='{schema}'\n",
    "                    ORDER BY ordinal_position'''\n",
    "c_names = engine.execute(table_name_sql).fetchall()\n",
    "c_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "f7369d37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flight_date',\n",
       " 'dep_time',\n",
       " 'sched_dep_time',\n",
       " 'dep_delay',\n",
       " 'arr_time',\n",
       " 'sched_arr_time',\n",
       " 'arr_delay',\n",
       " 'airline',\n",
       " 'tail_number',\n",
       " 'flight_number',\n",
       " 'origin',\n",
       " 'dest',\n",
       " 'air_time',\n",
       " 'actual_elapsed_time',\n",
       " 'distance',\n",
       " 'cancelled',\n",
       " 'diverted']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can clean up the results into a clean list\n",
    "new_column_names=[]\n",
    "for name in c_names:\n",
    "    new_column_names.append(name[0])\n",
    "new_column_names        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09331857",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just in case the above fails here are the results\n",
    "'''new_column_names_alternate = ['flight_date', 'dep_time', 'sched_dep_time', 'dep_delay', 'arr_time', 'sched_arr_time', \n",
    "                'arr_delay', 'airline', 'tail_number', 'flight_number', 'origin', 'dest', 'air_time', 'actual_elapsed_time', 'distance', 'cancelled', 'diverted' ]'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d59e6ec",
   "metadata": {},
   "source": [
    "b) With the next function, we make our csv file ready to be uploaded to SQL.  \n",
    "We only keep to above specified columns and convert the datatypes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "4c725271",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_airline_df(df):\n",
    "    '''\n",
    "    Transforms a df made from BTS csv file into a df that is ready to be uploaded to SQL\n",
    "    Set rows=0 for no filtering\n",
    "    '''\n",
    "\n",
    "    # Build dataframe including only the columns you want to keep\n",
    "    df_airline = df.loc[:,columns_to_keep]\n",
    "     \n",
    "    # Clean data types and NULLs\n",
    "    df_airline['FlightDate']= pd.to_datetime(df_airline['FlightDate'], yearfirst=True)\n",
    "    df_airline['CRSArrTime']= pd.to_numeric(df_airline['CRSArrTime'], downcast='integer', errors='coerce')\n",
    "    df_airline['Cancelled']= pd.to_numeric(df_airline['Cancelled'], downcast='integer')\n",
    "    df_airline['Diverted']= pd.to_numeric(df_airline['Diverted'], downcast='integer')\n",
    "    df_airline['ActualElapsedTime']= pd.to_numeric(df_airline['ActualElapsedTime'], downcast='integer', errors='coerce')\n",
    "    \n",
    "    # Rename columns\n",
    "    df_airline.columns = new_column_names\n",
    "    \n",
    "    return df_airline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "2a7b4082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flight_date</th>\n",
       "      <th>dep_time</th>\n",
       "      <th>sched_dep_time</th>\n",
       "      <th>dep_delay</th>\n",
       "      <th>arr_time</th>\n",
       "      <th>sched_arr_time</th>\n",
       "      <th>arr_delay</th>\n",
       "      <th>airline</th>\n",
       "      <th>tail_number</th>\n",
       "      <th>flight_number</th>\n",
       "      <th>origin</th>\n",
       "      <th>dest</th>\n",
       "      <th>air_time</th>\n",
       "      <th>actual_elapsed_time</th>\n",
       "      <th>distance</th>\n",
       "      <th>cancelled</th>\n",
       "      <th>diverted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>957.0</td>\n",
       "      <td>1000</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1144.0</td>\n",
       "      <td>1212</td>\n",
       "      <td>-28.0</td>\n",
       "      <td>OO</td>\n",
       "      <td>N8903A</td>\n",
       "      <td>3984</td>\n",
       "      <td>MSP</td>\n",
       "      <td>ICT</td>\n",
       "      <td>85.0</td>\n",
       "      <td>107.0</td>\n",
       "      <td>545.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>924.0</td>\n",
       "      <td>840</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1058.0</td>\n",
       "      <td>1031</td>\n",
       "      <td>27.0</td>\n",
       "      <td>OO</td>\n",
       "      <td>N771SK</td>\n",
       "      <td>3989</td>\n",
       "      <td>DTW</td>\n",
       "      <td>RIC</td>\n",
       "      <td>63.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>1134.0</td>\n",
       "      <td>1106</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1318.0</td>\n",
       "      <td>1252</td>\n",
       "      <td>26.0</td>\n",
       "      <td>OO</td>\n",
       "      <td>N771SK</td>\n",
       "      <td>3989</td>\n",
       "      <td>RIC</td>\n",
       "      <td>DTW</td>\n",
       "      <td>76.0</td>\n",
       "      <td>104.0</td>\n",
       "      <td>456.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>1052</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>1146.0</td>\n",
       "      <td>1148</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>OO</td>\n",
       "      <td>N931EV</td>\n",
       "      <td>3991</td>\n",
       "      <td>CHA</td>\n",
       "      <td>ATL</td>\n",
       "      <td>29.0</td>\n",
       "      <td>57.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-12-18</td>\n",
       "      <td>1104.0</td>\n",
       "      <td>1044</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1414.0</td>\n",
       "      <td>1359</td>\n",
       "      <td>15.0</td>\n",
       "      <td>OO</td>\n",
       "      <td>N274SY</td>\n",
       "      <td>3993</td>\n",
       "      <td>BNA</td>\n",
       "      <td>LGA</td>\n",
       "      <td>114.0</td>\n",
       "      <td>130.0</td>\n",
       "      <td>764.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  flight_date  dep_time  sched_dep_time  dep_delay  arr_time  sched_arr_time  \\\n",
       "0  2018-12-18     957.0            1000       -3.0    1144.0            1212   \n",
       "1  2018-12-18     924.0             840       44.0    1058.0            1031   \n",
       "2  2018-12-18    1134.0            1106       28.0    1318.0            1252   \n",
       "3  2018-12-18    1049.0            1052       -3.0    1146.0            1148   \n",
       "4  2018-12-18    1104.0            1044       20.0    1414.0            1359   \n",
       "\n",
       "   arr_delay airline tail_number  flight_number origin dest  air_time  \\\n",
       "0      -28.0      OO      N8903A           3984    MSP  ICT      85.0   \n",
       "1       27.0      OO      N771SK           3989    DTW  RIC      63.0   \n",
       "2       26.0      OO      N771SK           3989    RIC  DTW      76.0   \n",
       "3       -2.0      OO      N931EV           3991    CHA  ATL      29.0   \n",
       "4       15.0      OO      N274SY           3993    BNA  LGA     114.0   \n",
       "\n",
       "   actual_elapsed_time  distance  cancelled  diverted  \n",
       "0                107.0     545.0          0         0  \n",
       "1                 94.0     456.0          0         0  \n",
       "2                104.0     456.0          0         0  \n",
       "3                 57.0     106.0          0         0  \n",
       "4                130.0     764.0          0         0  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Call function and check resulting dataframe\n",
    "df_clean = clean_airline_df(df)\n",
    "df_clean.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b742a452",
   "metadata": {},
   "source": [
    "If you decide to only look at specific airports, it is a good decision to filter for them in advance.  \n",
    "This function does the filtering. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "a42676a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the airports you are interested in and put them as a list in the function.\n",
    "def select_airport(df, airports):\n",
    "    ''' Helper function for filtering the airline dataframe for a subset of airports'''\n",
    "    df_out = df.loc[(df.origin.isin(airports)) | (df.dest.isin(airports))]\n",
    "    return df_out"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7f0efbd8",
   "metadata": {},
   "source": [
    "#### Selecting the Airports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "339add17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1297165, 17)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute function, filtering for area airports\n",
    "airports=['ATL', 'DFW', 'DEN', 'ORD', 'LAX', 'JFK', 'EWR', 'LGA']\n",
    "if len(airports) > 0:\n",
    "    df_selected_airports = select_airport(df_clean, airports)\n",
    "else:\n",
    "    df_selected_airports = df_clean\n",
    "    \n",
    "df_selected_airports.head()\n",
    "\n",
    "df_selected_airports.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635eaad3",
   "metadata": {},
   "source": [
    "# 3. Push the prepared data to a table in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e697f3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Engine(postgresql://user:***@host/database)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "engine #Testing the output to see if it is connected to sql_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a45a3970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The flights_api_sql_group3 table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "# Example: flights_sp for Sina's flights table, flights_groupname or similar\n",
    "table_name = 'flights_api_sql_group3'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_selected_airports.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "\n",
    "# It took 43 minutes :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4bcdcb6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_selected_airports.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
